{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-15T15:26:26.711624Z",
     "start_time": "2024-11-15T15:26:26.513417Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "\n",
    "# Path to your CSV file\n",
    "path_train = 'data/train_data.npy'\n",
    "path_test = 'data/test_data.npy'\n",
    "path_test_label = 'data/test_labels.npy'\n",
    "\n",
    "# Read the CSV file into a DataFrame\n",
    "train = np.load(path_train)\n",
    "test = np.load(path_test)\n",
    "test_labels = np.load(path_test_label)"
   ],
   "id": "43879df55401fc46",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-15T15:26:40.241314Z",
     "start_time": "2024-11-15T15:26:40.227978Z"
    }
   },
   "cell_type": "code",
   "source": [
    "data = test\n",
    "labels = test_labels"
   ],
   "id": "3fc085e752b3a50e",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Ideas: Look at papers about anomaly detection (using autoencoders)\n",
    "# Do hyperparam search on lr and percentile"
   ],
   "id": "dff3097bd6ddbf54"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-15T16:02:40.693117Z",
     "start_time": "2024-11-15T15:59:31.098695Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "# Scale the data\n",
    "scaler = StandardScaler()\n",
    "data_scaled = scaler.fit_transform(data)\n",
    "\n",
    "# Split into training (normal data) and testing sets\n",
    "X_train = train\n",
    "X_test = test\n",
    "y_test = test_labels\n",
    "\n",
    "#X_train, X_test, y_train, y_test = train_test_split(data_scaled, labels, test_size=0.2, random_state=42)\n",
    "#X_train = X_train[y_train == 0]  # Train only on normal data\n",
    "\n",
    "# Convert data to PyTorch tensors\n",
    "X_train = torch.tensor(X_train, dtype=torch.float32)\n",
    "X_test = torch.tensor(X_test, dtype=torch.float32)\n",
    "y_test = torch.tensor(y_test, dtype=torch.float32)\n",
    "\n",
    "# Define the autoencoder model\n",
    "class Autoencoder(nn.Module):\n",
    "    \n",
    "    #lr = 0.001\n",
    "    lr = 0.0001\n",
    "    percentile = 90\n",
    "    def __init__(self, input_dim):\n",
    "        super(Autoencoder, self).__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(input_dim, 14),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(14, 7),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(7, 3),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(3, 7),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(7, 14),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(14, input_dim),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        encoded = self.encoder(x)\n",
    "        decoded = self.decoder(encoded)\n",
    "        return decoded\n",
    "\n",
    "# Instantiate the model, define the loss function and optimizer\n",
    "input_dim = X_train.shape[1]\n",
    "model = Autoencoder(input_dim)\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=model.lr)\n",
    "\n",
    "# Train the autoencoder\n",
    "num_epochs = 10\n",
    "batch_size = 64\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    permutation = torch.randperm(X_train.size()[0])\n",
    "    for i in range(0, X_train.size()[0], batch_size):\n",
    "        indices = permutation[i:i + batch_size]\n",
    "        batch_x = X_train[indices]\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(batch_x)\n",
    "        loss = criterion(outputs, batch_x)\n",
    "\n",
    "        # Backward pass and optimization\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    print(f'Epoch [{epoch + 1}/{num_epochs}], Loss: {loss.item():.4f}')\n",
    "\n",
    "# Use the autoencoder to reconstruct the test data\n",
    "X_test_pred = model(X_test).detach().numpy()\n",
    "\n",
    "# Calculate reconstruction error\n",
    "mse = np.mean((X_test.numpy() - X_test_pred) ** 2, axis=1)\n",
    "\n",
    "# Set a threshold for anomaly detection (e.g., 95th percentile)\n",
    "threshold = np.percentile(mse, model.percentile)\n",
    "\n",
    "# Identify anomalies\n",
    "anomalies = mse > threshold\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test.numpy(), anomalies)\n",
    "precision = precision_score(y_test.numpy(), anomalies)\n",
    "recall = recall_score(y_test.numpy(), anomalies)\n",
    "f1 = f1_score(y_test.numpy(), anomalies)\n",
    "\n",
    "print(f\"Parameters: lr: {model.lr}, percentile: {model.percentile}\")\n",
    "print(f\"Number of total samples: {len(X_test)}\")\n",
    "print(f\"Number of predicted anomalies: {np.sum(anomalies)}\")\n",
    "print(f\"Number of actual anomalies: {np.sum(y_test.numpy())}\")\n",
    "print(f\"Accuracy: {accuracy:.2f}\")\n",
    "print(f\"Precision: {precision:.2f}\")\n",
    "print(f\"Recall: {recall:.2f}\")\n",
    "print(f\"F1-score: {f1:.2f}\")"
   ],
   "id": "5719d136f9879d7e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Loss: 0.0140\n",
      "Epoch [2/10], Loss: 0.0093\n",
      "Epoch [3/10], Loss: 0.0035\n",
      "Epoch [4/10], Loss: 0.0053\n",
      "Epoch [5/10], Loss: 0.0070\n",
      "Epoch [6/10], Loss: 0.0025\n",
      "Epoch [7/10], Loss: 0.0025\n",
      "Epoch [8/10], Loss: 0.0031\n",
      "Epoch [9/10], Loss: 0.0024\n",
      "Epoch [10/10], Loss: 0.0019\n",
      "Parameters: lr: 0.0001, percentile: 90\n",
      "Number of total samples: 449919\n",
      "Number of predicted anomalies: 44992\n",
      "Number of actual anomalies: 54584.0\n",
      "Accuracy: 0.94\n",
      "Precision: 0.79\n",
      "Recall: 0.65\n",
      "F1-score: 0.71\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-15T15:47:09.362103Z",
     "start_time": "2024-11-15T15:47:09.349018Z"
    }
   },
   "cell_type": "code",
   "source": [
    "'''\n",
    "percentile: 95\n",
    "\n",
    "Epoch [50/50], Loss: 0.4138\n",
    "Number of total samples: 89984\n",
    "Number of predicted anomalies: 4500\n",
    "Number of actual anomalies: 11032.0\n",
    "Accuracy: 0.91\n",
    "Precision: 0.86\n",
    "Recall: 0.35\n",
    "F1-score: 0.50\n",
    "'''\n",
    "\n",
    "'''\n",
    "Epoch [10/10], Loss: 0.0019\n",
    "Parameters: lr: 0.0001, percentile: 90\n",
    "Number of total samples: 449919\n",
    "Number of predicted anomalies: 44992\n",
    "Number of actual anomalies: 54584.0\n",
    "Accuracy: 0.94\n",
    "Precision: 0.79\n",
    "Recall: 0.65\n",
    "F1-score: 0.71\n",
    "'''"
   ],
   "id": "d5a49d181bed42f6",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\npercentile: 95\\n\\nEpoch [50/50], Loss: 0.4138\\nNumber of total samples: 89984\\nNumber of predicted anomalies: 4500\\nNumber of actual anomalies: 11032.0\\nAccuracy: 0.91\\nPrecision: 0.86\\nRecall: 0.35\\nF1-score: 0.50\\n'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "4aca56047ead5806"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
